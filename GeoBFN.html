<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="description"
        content="Enigmata: Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles" />
    <meta name="keywords, puzzle, logical, reasoning, large lanuge model, LLM"
        content="Enigmata" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Enigmata: Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet" />
    <link rel="stylesheet" href="./css/bulma.min.css" />
    <link rel="stylesheet" href="./css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./css/bulma-slider.min.css" />
    <link rel="stylesheet" href="./css/fontawesome.all.min.css" />
    <!-- <link rel="stylesheet" href="./css/fontawesome_6_7_2.all.css" /> -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" />
    <link rel="stylesheet" href="./css/index.css" />
    <link rel="stylesheet" href="./css/enhanced-styles.css" />
    <link rel="stylesheet" href="./css/final-enhancements.css" />
    <link rel="stylesheet" href="./css/navbar-fix.css" />
    <link rel="stylesheet" href="./css/navbar-alignment-fix.css" />
    <link rel="stylesheet" href="./css/overlap-fix.css" />
    <link rel="stylesheet" href="./css/spacing-fix.css" />
    <link rel="stylesheet" href="./css/author-affiliation-styles.css" />
    <link rel="icon" href="./assets/doubao.png" type="image/png" />
    <!-- add page icon at 64 x 64-->
    <!-- <link rel="icon" type="image/png" href="./assets/re.png" sizes="256x256" /> -->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./js/fontawesome.all.min.js"></script>
    <script src="./js/bulma-carousel.min.js"></script>
    <script src="./js/bulma-slider.min.js"></script>
    <script src="./js/index.js"></script>
    <script src="./js/enhanced-animations.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>

    <style>
        .menu {
          position: fixed;
          top: 20rem;
          left: 8rem;
          width: 10rem;
        }
        .main-content {
          margin-left: 10rem;
          padding-top: 20rem;
        }
        .hero {
            width: 80rem;
        }
    </style>
</head>


    



<body>


    <!-- Sidebar -->
    <aside class="menu" >
        <p class="menu-label">GeoBFN</p>
        <ul class="menu-list">
            <li><a href="#introduction">Introduction</a></li>
            <li><a href="#eval">Evaluation</a></li>
            <li><a href="#model">Model</a></li>
            <li><a href="#citation">Citation</a></li>
        </ul>
    </aside>

    
    

    
    <div class="container">

        
        <section class="hero">
            <div class="hero-body">
                <div class="container">
                    <div class="has-text-centered">
                        <h1 class="publication-title">
                            <em class="dnerf">Enigmata</em>: Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles
                        </h1>
                        <div class="publication-authors">
                            <span class="author-block"><a href="https://jiangjiechen.github.io/">Jiangjie Chen</a><sup>1,6,*,‚Ä†</sup></span>
                            <span class="author-block"><a href="https://abbey4799.github.io/">Qianyu He</a><sup>1,2,‚Ä†</sup></span>
                            <span class="author-block"><a href="https://siyuyuan.github.io/">Siyu Yuan</a><sup>1,2,‚Ä†</sup></span>
                            <span class="author-block"><a href="https://scholar.google.com/citations?user=FAJzMAQAAAAJ&hl=zh-CN">Aili Chen</a><sup>2,‚Ä†</sup></span><br>
                            <span class="author-block"><a href="https://scholar.google.com/citations?hl=zh-CN&user=9wBz7NkAAAAJ">Zhicheng Cai</a><sup>6,4</sup></span>
                            <span class="author-block"><a href="https://seed-enigmata.github.io/">Weinan Dai</a><sup>1,3,6</sup></span>
                            <span class="author-block"><a href="https://seed-enigmata.github.io/">Hongli Yu</a><sup>1,3,6</sup></span>
                            <span class="author-block"><a href="https://yqy2001.github.io/">Qiying Yu</a><sup>1,3,6</sup></span>
                            <span class="author-block"><a href="https://scholar.google.com/citations?user=DDRBbxgAAAAJ&hl=zh-CN">Xuefeng Li</a><sup>1,5</sup></span>
                            <span class="author-block"><a href="https://scholar.google.com/citations?user=Vt1j3kEAAAAJ&hl=zh-CN">Jiaze Chen</a><sup>1</sup></span>
                            <span class="author-block"><a href="https://zhouh.github.io/">Hao Zhou</a><sup>3,6</sup></span>
                            <span class="author-block"><a href="https://mingxuan.github.io/">Mingxuan Wang</a><sup>1,6</sup></span>
                        </div>
                        <div class="publication-affiliations">
                            <span class="affiliation-block"><sup>1</sup>ByteDance Seed</span><br>
                            <span class="affiliation-block"><sup>2</sup>Fudan University</span>
                            <span class="affiliation-block"><sup>3</sup>Institute for AI Industry Research (AIR), Tsinghua University</span><br>
                            <span class="affiliation-block"><sup>4</sup>Nanjing University</span>
                            <span class="affiliation-block"><sup>5</sup>Shanghai Jiao Tong University</span><br>
                            <span class="affiliation-block"><sup>6</sup>SIA-Lab of Tsinghua AIR and ByteDance Seed</span>
                            <div class="affiliation-note">*Project Lead; ‚Ä†Equal Contribution</div>
                            <div class="affiliation-note">Contact: <a href="mailto:jiangjiec@bytedance.com">jiangjiec@bytedance.com</a></div>
                        </div>
                        <div class="publication-links">
                            <span class="link-block">
                                <a href="http://arxiv.org/abs/2505.19914" class="external-link button is-dark">
                                    <span class="icon">
                                        <i class="fas fa-file-pdf"></i>
                                    </span>
                                    <span>Paper</span>
                                </a>
                            </span>
                            <span class="link-block">
                                <a href="GitHub - BytedTsinghua-SIA/Enigmata: Resources for the Enigmata Project." class="external-link button is-dark">
                                    <span class="icon">
                                        <i class="fas fa-database"></i>
                                    </span>
                                    <span>Code</span>
                                </a>
                            </span>
                            <span class="link-block">
                                <a href="https://huggingface.co/datasets/BytedTsinghua-SIA/Enigmata-Eval" class="external-link button is-dark">
                                    <span class="icon">
                                        <i class="fas fa-database"></i>
                                    </span>
                                    <span>Evaluation</span>
                                </a>
                            </span>
                            <span class="link-block">
                                <a href="https://huggingface.co/BytedTsinghua-SIA/Enigmata-Qwen2.5-32B" class="external-link button is-dark">
                                    <span class="icon">
                                        ü§ó
                                    </span>
                                    <span>Model</span>
                                </a>
                            </span>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        
        <!-- Main content -->

        

        
        <nav class="navbar is-fixed-top" role="navigation" aria-label="section navigation">
            <div class="container">
                <div class="navbar-brand">
                    <a class="navbar-item" href="#">
                        üß© Enigmata
                    </a>
                    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
                        <span aria-hidden="true"></span>
                        <span aria-hidden="true"></span>
                        <span aria-hidden="true"></span>
                    </a>
                </div>
                <div class="navbar-menu">
                    <div class="navbar-end">
                        <a class="navbar-item" href="index.html">Home</a>
                        <a class="navbar-item" href="GeoBFN.html">GeoBFN</a>
                        <a class="navbar-item" href="MolCRAFT.html">MolCRAFT</a>
                        <a class="navbar-item" href="CysBFN.html">CysBFN</a>
                        <a class="navbar-item" href="ProfileBFN.html">ProfileBFN</a>
                        <a class="navbar-item" href="BFN42Dgraph.html">BFN42Dgraph</a>
                        <a class="navbar-item" href="MolJO.html">MolJO</a>
                        <a class="navbar-item" href="MolPilot.html">MolPilot</a>
                        <a class="navbar-item" href="Others.html">Others</a>
                    </div>
                </div>
            </div>
        </nav>



            <section class="section" id="introduction">
                <div class="container">
        
                    <div class="columns is-centered">
                        <div class="column is-10">
                            <h2 class="title is-3">Introduction</h2>
                            <div class="content">
                                <p>
                                    We introduce <strong>Enigmata</strong>, the first comprehensive suite tailored for improving LLMs with puzzle reasoning skills, which integrates seamlessly with reinforcement learning using verifiable rule-based rewards.
                                </p>
                                
                                <p> <strong>Enigmata-Data</strong> includes 36 tasks across 7 categories, each with: 1) a generator that produces unlimited examples with controllable difficulty, and 2) a rule-based verifier for automatic evaluation. This generator-verifier design supports scalable, multi-task RL training, fine-grained analysis, and seamless RLVR integration.
                                We further propose <strong>Enigmata-Eval</strong>, a rigorous benchmark for assessing puzzle reasoning abilities and guiding research on generalizable reasoning models.                            
                                    </p>
        
                                    <p><strong>Qwen2.5-32B-Enigmata</strong>, trained with RLVR, consistently surpasses o3-mini-high and o1 on the puzzle reasoning benchmarks like Enigmata-Eval, ARC-AGI, and ARC-AGI 2. It also generalizes well to out-of-domain puzzle benchmarks and mathematical reasoning, with little multitasking trade-off.</p>
                                    <p>When trained on <strong>larger models like Seed1.5-Thinking</strong> (20B activated parameters and 200B total parameters), puzzle data from Enigmata further boosts SoTA performance on advanced math and STEM reasoning tasks such as AIME (2024-2025), BeyondAIME and GPQA (Diamond), showing nice generalization benefits of Enigmata.
                                    </p>
                                
                                    <strong><em style="color: #3a76ed"><center>We hope Enigmata serves as a solid foundation for the community to push forth the research on reasoning models!</center></em></strong>
                                <!-- <p>
                                    Our key contributions are:
                                    <ul>
                                        <li>We introduce Enigmata, the first suite for enabling LLMs with advanced and comprehensive logical reasoning abilities for solving puzzles.</li>
                                        <li>The Enigmata suite consists of Enigmata-Data, featuring <strong>36 distinct tasks across 7 categories</strong> with
                                            controllable difficulty, scalable generation, and automatic verification, which seamlessly fit the RLVR
                                            training paradigm.</li>
                                        <li>We establish Enigmata-Eval, a benchmark that rigorously and comprehensively evaluates puzzle
                                            reasoning abilities, and propose the Enigmata-Model recipe that trains models with superior performance
                                            on in-domain and OOD puzzle reasoning tasks.</li>
                                        </ul> -->
        
                            </div>
                        </div>
                    </div>
        
                </div>
            </section>
          


            <section class="section" id="eval">
                <div class="container">
                    <div class="columns is-centered">
                        <div class="column is-10">
                            <h2 class="title is-3">‚öñÔ∏è Enigmata-Eval: Evaluating Logical Reasoning Capabilities</h2>
                            <div class="content">
                                <p>Enigmata-Eval is a comprehensive benchmark containing 4,758 puzzle instances across Easy, Medium, and Hard difficulty levels. Each task provides 50 instances per difficulty level where possible, with strict train-eval separation to prevent data leakage.</p>
        
                                <p>üì• <strong>Download Enigmata-Eval</strong>: <a href="https://huggingface.co/datasets/BytedTsinghua-SIA/Enigmata-Eval">HuggingFace Dataset</a></p>
                            
                 
        
                        
                        
                        
                        </div>
                    </div>
                </div>
            </section>
        
            
            <section class="section" id="model">
                <div class="container">
                    <div class="columns is-centered">
                        <div class="column is-10">
                            <h2 class="title is-3">ü§ñ Enigmata-Model: The Training Recipe</h2>
                            <div class="content">
                                <p>Our training methodology follows a two-stage process designed to systematically build reasoning abilities: 
                                    (1) rejection fine-tuning to establish foundational reasoning patterns, and 
                                    (2) multi-task RL to develop general reasoning skills that transfer across diverse problem domains.</p>
                            </div>
                            <div class="content">
                                <div
                                style="background-color: #f8fafc; border-radius: 12px; border-left: 6px solid #3a76ed; padding: 1.2rem; margin-bottom: 1.5rem;">
                                    <div style="display: flex; flex-direction: column; gap: 0.8rem;">
                                        <div style="display: flex; align-items: flex-start; gap: 0.8rem;"> 
                                            <div
                                                style="background-color: #3a76ed; color: white; padding: 0.4rem; border-radius: 50%; font-size: 0.9rem; display: flex; align-items: center; justify-content: center; min-width: 2rem; height: 2rem;">
                                                1
                                            </div>
                                            <div>
                                                <p style="margin: 0; line-height: 1.4;"><strong>Rejection Fine-tuning:</strong>
                                                    This initial stage focuses on building foundational reasoning by fine-tuning the model with high-quality solutions from a balanced mix of math and puzzle problems, including ARC-AGI.</p>
                                            </div>
                                        </div>
                                
                                        <div style="display: flex; align-items: flex-start; gap: 0.8rem;">
                                            <div
                                                style="background-color: #3a76ed; color: white; padding: 0.4rem; border-radius: 50%; font-size: 0.9rem; display: flex; align-items: center; justify-content: center; min-width: 2rem; height: 2rem;">
                                                2
                                            </div>
                                            <div>
                                            <p style="margin: 0; line-height: 1.4;"><strong>RL with Verifiable Puzzles:</strong> The model then undergoes reinforcement learning using VC-PPO, where an automated verifier for puzzles provides immediate rewards, enabling an automatic RL pipeline for puzzle reasoning.</p>
                                            </div>
                                        </div>
        
                                        <div style="display: flex; align-items: flex-start; gap: 0.8rem;">
                                            <div
                                                style="background-color: #3a76ed; color: white; padding: 0.4rem; border-radius: 50%; font-size: 0.9rem; display: flex; align-items: center; justify-content: center; min-width: 2rem; height: 2rem;">
                                                3
                                            </div>
                                            <div>
                                                <p style="margin: 0; line-height: 1.4;"><strong>Multi-task Training:</strong> To develop general and transferable logical reasoning, the training incorporates multi-task methods like Mix-training RL and Multi-stage RL, combining diverse puzzle types (Enigmata, ARC-AGI) with challenging mathematical problems (AIME) while maintaining a balanced ratio.</p>
                                            </div>
                                        </div>                                
                                </div>
                            </div>
                            </div>
        
                            
                            <div class="content">
                                <h4>üëÄ Experimental Results</h4>
                                <div class="content">
                                    <p>Our model, specifically the 32B parameter version, significantly outperforms most public models on Enigmata-Eval and ARC-AGI, showcasing enhanced general logical reasoning. This success stems from effective rejection fine-tuning (RFT) and multi-task RL strategies, which improve generalization while preserving existing math reasoning abilities.</p>
                                </div>
                                <figure>
                                    <img src="./assets/main_results_1.png" alt="A descriptive alt text for your image" style="width: 600px;">
                                    <figcaption style="color: gray;">Performance of reasoning, generic, and our trained LLMs on reasoning benchmarks</figcaption>
                                  </figure>
                                
                                  <div class="content">
                                    <p>On Enigmata-Eval, our Qwen2.5-32B-Enigmata model excels in Crypto, Arithmetic, and Logic tasks, indicating strong rule-based reasoning. It also performs competitively in search tasks, though spatial and sequential categories remain challenging.</p>
                                </div>
        
                                  <figure>
                                    <img src="./assets/main_results2.png" alt="A descriptive alt text for your image" style="width: 600px;">
                                    <figcaption style="color: gray;">Performance of reasoning LLMs, generic LLMs, and our trained LLMs on Enigmata-Eval</figcaption>
                                  </figure>
        
                            </div>
        
                            
                            <div class="content">
                                <h4>üåü Generalization with Scaling: Free Lunch from Enigmata </h4>
                            <div class="content">
                                <p>Incorporating the <strong>Enigmata-Data</strong> synthetic puzzle dataset into large-scale model training, e.g., <a href="https://arxiv.org/abs/2504.13914">Seed1.5-Thinking</a>, surprisingly improving performance on challenging benchmarks like AIME and GPQA Diamond. This demonstrates an unexpected <strong>generalization benefit</strong> for advanced reasoning models.</p>
                            </div>
        
                              <figure>
                                <img src="./assets/seed_thinking.png" alt="A descriptive alt text for your image" style="width: 600px;">
                                <figcaption style="color: gray;">Results on benchmarks for general reasoning capabilities</figcaption>
                              </figure>
                            </div>
                        </div>
                    </div>
                </div>
            </section>


            <section class="section" id="citation">
                <div class="container">
                    <div class="columns is-centered">
                        <div class="column is-10">
                            <h2 class="title is-3">üìù Citation</h2>
                            <div class="content">
                                <p>If you find this work useful, please cite our paper:</p>
                                <pre><code class="latex">
        @article{chen2025enigmata,
            title={Enigmata: Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles},
            author={Chen, Jiangjie and He, Qianyu and Yuan, Siyu and Chen, Aili and Cai, Zhicheng and Dai, Weinan and Yu, Hongli and Yu, Qiying and Li, Xuefeng and Chen, Jiaze and others},
            journal={arXiv preprint arXiv:2505.19914},
            year={2025}
        }
                                </code></pre>
                            </div>
                        </div>
                    </div>
                </div>
            </section>
          
          <!-- ‚Ä¶ other sections ‚Ä¶ -->
        </div>
  </body>




</html>